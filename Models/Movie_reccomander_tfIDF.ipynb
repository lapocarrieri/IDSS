{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":679},"id":"C45uHqFL3KA4","outputId":"4855d012-df33-4ab8-b240-5705f8f5f6bf","executionInfo":{"status":"ok","timestamp":1673706733218,"user_tz":-60,"elapsed":77547,"user":{"displayName":"Lapo Carrieri","userId":"04747310432017034124"}}},"outputs":[{"output_type":"display_data","data":{"text/html":["        <script type=\"text/javascript\">\n","        window.PlotlyConfig = {MathJaxConfig: 'local'};\n","        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n","        if (typeof require !== 'undefined') {\n","        require.undef(\"plotly\");\n","        requirejs.config({\n","            paths: {\n","                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n","            }\n","        });\n","        require(['plotly'], function(Plotly) {\n","            window._Plotly = Plotly;\n","        });\n","        }\n","        </script>\n","        "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting scikit-surprise\n","  Downloading scikit-surprise-1.1.3.tar.gz (771 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m772.0/772.0 KB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-surprise) (1.2.0)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from scikit-surprise) (1.21.6)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit-surprise) (1.7.3)\n","Building wheels for collected packages: scikit-surprise\n","  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.3-cp38-cp38-linux_x86_64.whl size=2626453 sha256=920fb0ba3b95970bb173c72d92f50b6a48c731c6407fb60e4850a692806a6699\n","  Stored in directory: /root/.cache/pip/wheels/af/db/86/2c18183a80ba05da35bf0fb7417aac5cddbd93bcb1b92fd3ea\n","Successfully built scikit-surprise\n","Installing collected packages: scikit-surprise\n","Successfully installed scikit-surprise-1.1.3\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting lightfm\n","  Downloading lightfm-1.16.tar.gz (310 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.1/310.1 KB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from lightfm) (1.21.6)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.8/dist-packages (from lightfm) (1.7.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from lightfm) (2.25.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from lightfm) (1.0.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->lightfm) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->lightfm) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->lightfm) (1.24.3)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->lightfm) (4.0.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->lightfm) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->lightfm) (3.1.0)\n","Building wheels for collected packages: lightfm\n","  Building wheel for lightfm (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for lightfm: filename=lightfm-1.16-cp38-cp38-linux_x86_64.whl size=746186 sha256=73a978e2035d7aa5c1d0dca8ccec47fb2a36cc62a0fa9be0d6a66e95ed4805d4\n","  Stored in directory: /root/.cache/pip/wheels/ec/bb/51/9c487d021c1373b691d13cadca0b65b6852627b1f3f43550fa\n","Successfully built lightfm\n","Installing collected packages: lightfm\n","Successfully installed lightfm-1.16\n"]}],"source":["# To store the data\n","import pandas as pd\n","\n","# To do linear algebra\n","import numpy as np\n","\n","# To create plots\n","import matplotlib.pyplot as plt\n","\n","# To create interactive plots\n","from plotly.offline import init_notebook_mode, plot, iplot\n","import plotly.graph_objs as go\n","init_notebook_mode(connected=True)\n","\n","# To shift lists\n","from collections import deque\n","\n","# To compute similarities between vectors\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics.pairwise import cosine_similarity\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","# To use recommender systems\n","!pip install scikit-surprise\n","import surprise as sp\n","from surprise.model_selection import cross_validate\n","\n","# To create deep learning models\n","from keras.layers import Input, Embedding, Reshape, Dot, Concatenate, Dense, Dropout\n","from keras.models import Model\n","\n","# To create sparse matrices\n","from scipy.sparse import coo_matrix\n","\n","# To light fm\n","!pip3 install lightfm\n","from lightfm import LightFM\n","from lightfm.evaluation import precision_at_k\n","\n","# To stack sparse matrices\n","from scipy.sparse import vstack"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CY-xVilT7Dwo"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397},"id":"iIY5r00b3cNM","outputId":"76764d63-1d3f-40fd-b510-e3d96700a567","executionInfo":{"status":"error","timestamp":1673706733976,"user_tz":-60,"elapsed":415,"user":{"displayName":"Lapo Carrieri","userId":"04747310432017034124"}}},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-23887fa95f9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load data for all movies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m movie_titles = pd.read_csv('/content/drive/MyDrive/IDSS_PW3/archive.zip (Unzipped Files)/movie_titles.csv', \n\u001b[0m\u001b[1;32m      3\u001b[0m                            \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ISO-8859-1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                            \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                            names = ['Id', 'Year', 'Name']).set_index('Id')\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/IDSS_PW3/archive.zip (Unzipped Files)/movie_titles.csv'"]}],"source":["\n","# Load data for all movies\n","movie_titles = pd.read_csv('/content/drive/MyDrive/IDSS_PW3/archive.zip (Unzipped Files)/movie_titles.csv', \n","                           encoding = 'ISO-8859-1', \n","                           header = None, \n","                           names = ['Id', 'Year', 'Name']).set_index('Id')\n","\n","print('Shape Movie-Titles:\\t{}'.format(movie_titles.shape))\n","movie_titles.sample(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f41KshOy7Sg5"},"outputs":[],"source":["# Load a movie metadata dataset\n","movie_metadata = pd.read_csv('/content/drive/MyDrive/IDSS_PW3/archive (1)/movies_metadata.csv', low_memory=False)[['original_title', 'overview', 'vote_count']].set_index('original_title').dropna()\n","# Remove the long tail of rarly rated moves\n","movie_metadata = movie_metadata[movie_metadata['vote_count']>10].drop('vote_count', axis=1)\n","\n","print('Shape Movie-Metadata:\\t{}'.format(movie_metadata.shape))\n","movie_metadata.sample(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VibsC1qe7dE3"},"outputs":[],"source":["# Load single data-file\n","df_raw = pd.read_csv('/content/drive/MyDrive/IDSS_PW3/archive.zip (Unzipped Files)/combined_data_1.txt', header=None, names=['User', 'Rating', 'Date'], usecols=[0, 1, 2])\n","\n","\n","# Find empty rows to slice dataframe for each movie\n","tmp_movies = df_raw[df_raw['Rating'].isna()]['User'].reset_index()\n","movie_indices = [[index, int(movie[:-1])] for index, movie in tmp_movies.values]\n","\n","# Shift the movie_indices by one to get start and endpoints of all movies\n","shifted_movie_indices = deque(movie_indices)\n","shifted_movie_indices.rotate(-1)\n","\n","\n","# Gather all dataframes\n","user_data = []\n","\n","# Iterate over all movies\n","for [df_id_1, movie_id], [df_id_2, next_movie_id] in zip(movie_indices, shifted_movie_indices):\n","    \n","    # Check if it is the last movie in the file\n","    if df_id_1<df_id_2:\n","        tmp_df = df_raw.loc[df_id_1+1:df_id_2-1].copy()\n","    else:\n","        tmp_df = df_raw.loc[df_id_1+1:].copy()\n","        \n","    # Create movie_id column\n","    tmp_df['Movie'] = movie_id\n","    \n","    # Append dataframe to list\n","    user_data.append(tmp_df)\n","\n","# Combine all dataframes\n","df = pd.concat(user_data)\n","del user_data, df_raw, tmp_movies, tmp_df, shifted_movie_indices, movie_indices, df_id_1, movie_id, df_id_2, next_movie_id\n","print('Shape User-Ratings:\\t{}'.format(df.shape))\n","df.sample(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZreV12roGNqv"},"outputs":[],"source":["import plotly.graph_objects as go"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aUgMtEYQGsV7"},"outputs":[],"source":["plt.plot([1,2,3,4],[1,4,9,16])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YIenJ21_IbHz"},"outputs":[],"source":["import plotly\n","plotly.io.renderers.default = 'colab'\n","# example\n","import plotly.graph_objects as go\n","fig = go.Figure( go.Scatter(x=[1,2,3], y=[1,3,2] ) )\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"azH06Fx175WJ"},"outputs":[],"source":["# Get data\n","data = movie_titles['Year'].value_counts().sort_index()\n","\n","# Create trace\n","trace = go.Scatter(x = data.index,\n","                   y = data.values,\n","                   marker = dict(color = '#db0000'))\n","# Create layout\n","layout = dict(title = '{} Movies Grouped By Year Of Release'.format(movie_titles.shape[0]),\n","              xaxis = dict(title = 'Release Year'),\n","              yaxis = dict(title = 'Movies'))\n","\n","# Create plot\n","fig = go.Figure(data=[trace], layout=layout)\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HIpqlku08M-p"},"outputs":[],"source":["# Get data\n","data = df['Rating'].value_counts().sort_index(ascending=False)\n","\n","# Create trace\n","trace = go.Bar(x = data.index,\n","               text = ['{:.1f} %'.format(val) for val in (data.values / df.shape[0] * 100)],\n","               textposition = 'auto',\n","               textfont = dict(color = '#000000'),\n","               y = data.values,\n","               marker = dict(color = '#db0000'))\n","# Create layout\n","layout = dict(title = 'Distribution Of {} Netflix-Ratings'.format(df.shape[0]),\n","              xaxis = dict(title = 'Rating'),\n","              yaxis = dict(title = 'Count'))\n","# Create plot\n","fig = go.Figure(data=[trace], layout=layout)\n","iplot(fig)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tyHwc6GU8VJu"},"outputs":[],"source":["\n","# Filter sparse movies\n","min_movie_ratings = 10000\n","filter_movies = (df['Movie'].value_counts()>min_movie_ratings)\n","filter_movies = filter_movies[filter_movies].index.tolist()\n","\n","# Filter sparse users\n","min_user_ratings = 200\n","filter_users = (df['User'].value_counts()>min_user_ratings)\n","filter_users = filter_users[filter_users].index.tolist()\n","\n","# Actual filtering\n","df_filterd = df[(df['Movie'].isin(filter_movies)) & (df['User'].isin(filter_users))]\n","del filter_movies, filter_users, min_movie_ratings, min_user_ratings\n","print('Shape User-Ratings unfiltered:\\t{}'.format(df.shape))\n","print('Shape User-Ratings filtered:\\t{}'.format(df_filterd.shape))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kQOLkZEU8eXb"},"outputs":[],"source":["# Shuffle DataFrame\n","df_filterd = df_filterd.drop('Date', axis=1).sample(frac=1).reset_index(drop=True)\n","\n","# Testingsize\n","n = 100000\n","\n","# Split train- & testset\n","df_train = df_filterd[:-n]\n","df_test = df_filterd[-n:]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UWo-oOFu8khL"},"outputs":[],"source":["# Create a user-movie matrix with empty values\n","df_p = df_train.pivot_table(index='User', columns='Movie', values='Rating')\n","print('Shape User-Movie-Matrix:\\t{}'.format(df_p.shape))\n","df_p.sample(3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WClUhDxD8wdM"},"outputs":[],"source":["# Top n movies\n","n = 10\n","\n","# Compute mean rating for all movies\n","ratings_mean = df_p.mean(axis=0).sort_values(ascending=False).rename('Rating-Mean').to_frame()\n","\n","# Count ratings for all movies\n","ratings_count = df_p.count(axis=0).rename('Rating-Count').to_frame()\n","\n","# Combine ratings_mean, ratings_count and movie_titles\n","ranking_mean_rating = ratings_mean.head(n).join(ratings_count).join(movie_titles.drop('Year', axis=1))\n","\n","\n","# Join labels and predictions\n","df_prediction = df_test.set_index('Movie').join(ratings_mean)[['Rating', 'Rating-Mean']]\n","y_true = df_prediction['Rating']\n","y_pred = df_prediction['Rating-Mean']\n","\n","# Compute RMSE\n","rmse = np.sqrt(mean_squared_error(y_true=y_true, y_pred=y_pred))\n","\n","\n","# Create trace\n","trace = go.Bar(x = ranking_mean_rating['Rating-Mean'],\n","               text = ranking_mean_rating['Name'].astype(str) +': '+ ranking_mean_rating['Rating-Count'].astype(str) + ' Ratings',\n","               textposition = 'outside',\n","               textfont = dict(color = '#000000'),\n","               orientation = 'h',\n","               y = list(range(1, n+1)),\n","               marker = dict(color = '#db0000'))\n","# Create layout\n","layout = dict(title = 'Ranking Of Top {} Mean-Movie-Ratings: {:.4f} RMSE'.format(n, rmse),\n","              xaxis = dict(title = 'Mean-Rating',\n","                          range = (4.3, 4.55)),\n","              yaxis = dict(title = 'Movie'))\n","# Create plot\n","fig = go.Figure(data=[trace], layout=layout)\n","iplot(fig)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y6k9x8Hw85Ie"},"outputs":[],"source":["# Number of minimum votes to be considered\n","m = 1000\n","\n","# Mean rating for all movies\n","C = df_p.stack().mean()\n","\n","# Mean rating for all movies separatly\n","R = df_p.mean(axis=0).values\n","\n","# Rating count for all movies separatly\n","v = df_p.count().values\n","\n","\n","# Weighted formula to compute the weighted rating\n","weighted_score = (v/ (v+m) *R) + (m/ (v+m) *C)\n","# Sort ids to ranking\n","weighted_ranking = np.argsort(weighted_score)[::-1]\n","# Sort scores to ranking\n","weighted_score = np.sort(weighted_score)[::-1]\n","# Get movie ids\n","weighted_movie_ids = df_p.columns[weighted_ranking]\n","\n","\n","# Join labels and predictions\n","df_prediction = df_test.set_index('Movie').join(pd.DataFrame(weighted_score, index=weighted_movie_ids, columns=['Prediction']))[['Rating', 'Prediction']]\n","y_true = df_prediction['Rating']\n","y_pred = df_prediction['Prediction']\n","\n","# Compute RMSE\n","rmse = np.sqrt(mean_squared_error(y_true=y_true, y_pred=y_pred))\n","\n","\n","# Create DataFrame for plotting\n","df_plot = pd.DataFrame(weighted_score[:n], columns=['Rating'])\n","df_plot.index = weighted_movie_ids[:10]\n","ranking_weighted_rating = df_plot.join(ratings_count).join(movie_titles)\n","del df_plot\n","\n","\n","# Create trace\n","trace = go.Bar(x = ranking_weighted_rating['Rating'],\n","               text = ranking_weighted_rating['Name'].astype(str) +': '+ ranking_weighted_rating['Rating-Count'].astype(str) + ' Ratings',\n","               textposition = 'outside',\n","               textfont = dict(color = '#000000'),\n","               orientation = 'h',\n","               y = list(range(1, n+1)),\n","               marker = dict(color = '#db0000'))\n","# Create layout\n","layout = dict(title = 'Ranking Of Top {} Weighted-Movie-Ratings: {:.4f} RMSE'.format(n, rmse),\n","              xaxis = dict(title = 'Weighted Rating',\n","                          range = (4.15, 4.6)),\n","              yaxis = dict(title = 'Movie'))\n","# Create plot\n","fig = go.Figure(data=[trace], layout=layout)\n","iplot(fig)\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8RuWvB_PHx0c"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UxLLtsdE9JT1"},"outputs":[],"source":["# User index for recommendation\n","user_index = 0\n","\n","# Number of similar users for recommendation\n","n_recommendation = 100\n","\n","# Plot top n recommendations\n","n_plot = 10\n","\n","\n","# Fill in missing values\n","df_p_imputed = df_p.T.fillna(df_p.mean(axis=1)).T\n","\n","# Compute similarity between all users\n","similarity = cosine_similarity(df_p_imputed.values)\n","\n","# Remove self-similarity from similarity-matrix\n","similarity -= np.eye(similarity.shape[0])\n","\n","\n","# Sort similar users by index\n","similar_user_index = np.argsort(similarity[user_index])[::-1]\n","# Sort similar users by score\n","similar_user_score = np.sort(similarity[user_index])[::-1]\n","\n","\n","# Get unrated movies\n","unrated_movies = df_p.iloc[user_index][df_p.iloc[user_index].isna()].index\n","\n","# Weight ratings of the top n most similar users with their rating and compute the mean for each movie\n","mean_movie_recommendations = (df_p_imputed.iloc[similar_user_index[:n_recommendation]].T * similar_user_score[:n_recommendation]).T.mean(axis=0)\n","\n","# Filter for unrated movies and sort results\n","best_movie_recommendations = mean_movie_recommendations[unrated_movies].sort_values(ascending=False).to_frame().join(movie_titles)\n","\n","\n","# Create user-id mapping\n","user_id_mapping = {id:i for i, id in enumerate(df_p_imputed.index)}\n","\n","prediction = []\n","# Iterate over all testset items\n","for user_id in df_test['User'].unique():\n","    \n","    # Sort similar users by index\n","    similar_user_index = np.argsort(similarity[user_id_mapping[user_id]])[::-1]\n","    # Sort similar users by score\n","    similar_user_score = np.sort(similarity[user_id_mapping[user_id]])[::-1]\n","    \n","    for movie_id in df_test[df_test['User']==user_id]['Movie'].values:\n","\n","        # Compute predicted score\n","        score = (df_p_imputed.iloc[similar_user_index[:n_recommendation]][movie_id] * similar_user_score[:n_recommendation]).values.sum() / similar_user_score[:n_recommendation].sum()\n","        prediction.append([user_id, movie_id, score])\n","        \n","\n","# Create prediction DataFrame\n","df_pred = pd.DataFrame(prediction, columns=['User', 'Movie', 'Prediction']).set_index(['User', 'Movie'])\n","df_pred = df_test.set_index(['User', 'Movie']).join(df_pred)\n","\n","\n","# Get labels and predictions\n","y_true = df_pred['Rating'].values\n","y_pred = df_pred['Prediction'].values\n","\n","# Compute RMSE\n","rmse = np.sqrt(mean_squared_error(y_true=y_true, y_pred=y_pred))\n","\n","\n","# Create trace\n","trace = go.Bar(x = best_movie_recommendations.iloc[:n_plot, 0],\n","               text = best_movie_recommendations['Name'],\n","               textposition = 'inside',\n","               textfont = dict(color = '#000000'),\n","               orientation = 'h',\n","               y = list(range(1, n_plot+1)),\n","               marker = dict(color = '#db0000'))\n","# Create layout\n","layout = dict(title = 'Ranking Of Top {} Recommended Movies For A User Based On Similarity: {:.4f} RMSE'.format(n_plot, rmse),\n","              xaxis = dict(title = 'Recommendation-Rating',\n","                           range = (4.1, 4.5)),\n","              yaxis = dict(title = 'Movie'))\n","# Create plot\n","fig = go.Figure(data=[trace], layout=layout)\n","iplot(fig)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OHKwNWmfIPp5"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hFhvwnjt8knm"},"outputs":[],"source":["# Create tf-idf matrix for text comparison\n","tfidf = TfidfVectorizer(stop_words='english')\n","tfidf_matrix = tfidf.fit_transform(movie_metadata['overview'].dropna())\n","\n","\n","# Compute cosine similarity between all movie-descriptions\n","similarity = cosine_similarity(tfidf_matrix)\n","# Remove self-similarity from matrix\n","similarity -= np.eye(similarity.shape[0])\n","\n","\n","# Get index of movie to find similar movies\n","movie = 'Batman Begins'\n","n_plot = 10\n","index = movie_metadata.reset_index(drop=True)[movie_metadata.index==movie].index[0]\n","\n","# Get indices and scores of similar movies\n","similar_movies_index = np.argsort(similarity[index])[::-1][:n_plot]\n","similar_movies_score = np.sort(similarity[index])[::-1][:n_plot]\n","\n","# Get titles of similar movies\n","similar_movie_titles = movie_metadata.iloc[similar_movies_index].index\n","\n","\n","# Create trace\n","trace = go.Bar(x = similar_movies_score,\n","               text = similar_movie_titles,\n","               textposition = 'inside',\n","               textfont = dict(color = '#000000'),\n","               orientation = 'h',\n","               y = list(range(1, n_plot+1)),\n","               marker = dict(color = '#db0000'))\n","# Create layout\n","layout = dict(title = 'Ranking Of Top {} Most Similar Movie Descriptions For \"{}\"'.format(n_plot, movie),\n","              xaxis = dict(title = 'Cosine TFIDF Description Similarity',\n","                           range = (0, 0.4)),\n","              yaxis = dict(title = 'Movie'))\n","# Create plot\n","fig = go.Figure(data=[trace], layout=layout)\n","iplot(fig)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}